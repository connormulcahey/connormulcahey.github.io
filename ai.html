<html>
<head>
	<meta charset="UTF-8">
	<title>AI: Should We Be Worried?</title>
	<link rel="stylesheet" href="style.css">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="shortcut icon" href="/favicon.png">
</head>
<body>
	<h1>AI: Should We Be Worried?</h1>
	<h2>Connor Mulcahey</h2>
	<h3 style="text-align: center;"><strong>4/25/2017</strong></h3>

	<br>

	<p>So, I'm a newcomer to machine learning and these days I learn best by targeted creativity and curiostiy. In the spirit of <em><a href="http://waitbutwhy.com/">Wait But Why</a></em> which got me interested in this topic in the first place, I'm trying something new with my learning where I document my curiosity via creativity and publish it on the web for others who had the same questions I did. Here goes nothing.</p>

	<hr>

	<p>The fundamental curiosity I have with regards to AI is not with bayesian classifiers, better content reccomendation systems, or understanding <a href="https://en.wikipedia.org/wiki/Deep_learning">concepts with mysterious sounding names</a> but rather with the technical underpinnings, timeline, and safety discussions surrounding the inception of <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">artificial general intelligence</a>, or <strong>AGI</strong>, as well as the risks posed by the <a href="">portability</a> and other powerful AI algorithms. Initially I became interested in this after reading the somewhat well known article on <a href="http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">WaitButWhy</a> which, which, while it intended as has received a fair bit of <a href="http://lukemuehlhauser.com/a-reply-to-wait-but-why-on-machine-superintelligence/">criticsm</a>, has introduced a lot more people to the topic.</p>

	<p>The article also lead me to read <em><a href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies">Superintelligence: Paths, Dangers, Strategies</a> by <a href="http://www.nickbostrom.com/">Nick Bostrom</a> along with some of his <a href="http://www.nickbostrom.com/fable/dragon.html">other</a> <a href="http://www.nickbostrom.com/existential/risks.html">existential</a> <a href="http://www.simulation-argument.com/simulation.html">crisis</a> <a href="http://www.anthropic-principle.com/?q=anthropic_bias">catalysts</a>.</p>

	 the most interesting thing I'd seen so far, learn how it works via recursive question asking, fiddle with the code, and explain it in a web page as if I was explaining it to my former self at the start of the project.</p>

	<p>My fundamental question I had going into this was the following: <em><strong>If </strong></em></p>

	<p>Here is the <a href="https://arxiv.org/pdf/1312.5602v1.pdf">paper</a> published on February 26th 2015. It was featured on the cover of <a href="http://www.nature.com/">Nature:</a></p>

	<img src="https://lh6.googleusercontent.com/-Je-VCqhBoCE/VO5DRi39teI/AAAAAAAAC_U/5wSiWJ4F1Gg/w506-h750/DeepMindNatureCover.jpg" alt="">

	<p>Here is a video demonstration:</p>

	<iframe width="560" height="315" src="https://www.youtube.com/embed/V1eYniJ0Rnk" frameborder="0" allowfullscreen></iframe>

	<p>And here is the code</p>

</body>
</html>
